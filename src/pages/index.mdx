---
layout: ../layouts/Layout.astro
title: 'Enabling 20-DoF ByteDexter Hand Dexterous Teleoperation through Human Motion Retargeting'
description: Simple project page template for your research paper, built with Astro and Tailwind CSS
favicon: favicon.svg
thumbnail: screenshot-light.png
---

import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";

import { ImageComparison } from "../components/ImageComparison.tsx";

import hardware from "../assets/hardware.mp4";
import retarget from "../assets/retarget.mp4";
import teleoperation_system from "../assets/teleoperation_system.png";
import hand_retargeting from "../assets/hand_retargeting.png";
import experiment from "../assets/experiment.png";
import long_horizon from "../assets/long_horizon.png";
import hand from "../assets/hand.png";


import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "ByteDance Seed",
      institution: "ByteDance",
      notes: [],
    },
  ]}
  conference=""
  links={[
    {
      name: "Paper",
      url: "https://github.com/RomanHauksson/academic-project-astro-template",
      icon: "ri:file-pdf-2-line",
    },
    {
      name: "Code",
      url: "https://github.com/RomanHauksson/academic-project-astro-template",
      icon: "ri:github-line",
    },
    {
      name: "arXiv",
      url: "https://github.com/RomanHauksson/academic-project-astro-template",
      icon: "academicons:arxiv",
    }
  ]}
  />

<Video source={hardware} />

<HighlightedSection>

## Abstract

Replicating human-level dexterity remains a fundamental robotics challenge, requiring integrated solutions from mechatronic design to the control of high degree-of-freedom (DoF) robotic hands. While imitation learning shows promise in transferring human dexterity to robots, the efficacy of trained policies relies on the quality of human demonstration data. We bridge this gap with a hand-arm teleoperation system featuring: (1) a 20-DoF linkage-driven anthropomorphic robotic hand  for biomimetic dexterity, and (2) an optimization-based motion retargeting for real-time, high-fidelity reproduction of intricate human hand motions and seamless hand–arm coordination. We validate the system via extensive empirical evaluations, including dexterous in-hand manipulation tasks and a long-horizon task requiring the organization of a cluttered makeup table randomly populated with nine objects. Experimental results demonstrate its intuitive teleoperation interface with real-time control and the ability to generate high-quality demonstration data. Please refer to the accompanying video for further details.

</HighlightedSection>

## Method

Our hand-arm teleoperation system achieves dexterous in-hand manipulation, including multi-object grasping, rotation, and regrasping. It also successfully manages grasping of various cosmetic items during a long-horizon cluttered-table organization task.

<Video source={retarget} />

### Robotic Hand-Arm Teleoperation System

<div>

ByteDexter’s four long fingers adopt the parallel–serial topology of [ILDA hand](https://example.com/paper.pdf), 
but this design proves unsuitable for the thumb. Two DoFs at the MCP joint are coupled by the parallel linkage. As MCP flexion increases, 
abduction/adduction range diminishes progressively—reaching zero in full flexion. Additionally, implementing thumb abduction/adduction with 
two actuators mounted perpendicular to the palm unavoidably thickens the palm profile, compromising compactness. To address these limitations, 
we developed a thumb kinematic structure that achieves decoupled, human‐like thumb mobility for advanced grasping and manipulation, allowing full-range MCP 
and PIP flexion across the thumb's MCP entire abduction (<LaTeX inline formula="-4^\circ \;\text{to}\; 90^\circ" />) span.

</div>

<Figure>
  <Image slot="figure" source={hand} altText="The proposed hand-arm teleoperation system." class="w-full" />
  <span slot="caption">The ByteDexter hand. (a) robotic finger with 2-DoF MCP joint, 1-DoF PIP
joint, with a passively actuated 1-DoF DIP joint, (b) the thumb’s kinematic structure, and (c) ByteDexter hand
with thumb motion from zero abduction to its full range.</span>
</Figure>

The teleoperation interface comprises a Meta Quest 3 headset to track wrist poses and a Manus Quantum Metaglove for hand motions. The Quest controller is mounted to Manus glove’s back via a custom holder to ensure synchronous tracking of wrist and finger movements. This setup delivers an intuitive, natural interface that enhances hand–arm coordination during teleoperation. On the robotic side, the ByteDexter anthropomorphic hand is mounted to a Franka Research 3 (FR3) arm, with its wrist–fingertip axis aligned to the arm’s seventh joint. The operators’ wrist poses from the Quest headset are mapped directly to the FR3 end-effector, while hand motions from the Manus Glove are retargeted into joint position commands for the ByteDexter hand.

<Figure>
  <Image slot="figure" source={teleoperation_system} altText="The proposed hand-arm teleoperation system." class="w-full" />
  <span slot="caption">The proposed hand-arm teleoperation system.</span>
</Figure>

### Hand Motion Retargeting

<div>
We retarget human hand pose data obtained from the Manus Glove into joint position references of the ByteDexter hand by solving an optimization problem that minimizes the difference between corresponding keyvectors in the robotic and human hand. 
The finger design of ByteDexter adopts anatomically proportional dimensions scaled to human finger lengths. However, the palm size is constrained to prioritize functional integration of motors, embedded boards, and leadscrews, resulting in a non-anthropomorphic structure that introduces morphological discrepancies with human palm anatomy. 
To address this non-anatomical factor, our approach diverges from prior methods using fingertip-to-wrist keyvectors; instead, we compute keyvectors from each fingertip to its own MCP joint. 
A keyvector is the 3D vector between a pair of key points, pointing from the origin of one coordinate frame to the other, expressed in the robot hand’s base frame. 
</div>

<TwoColumns>
  <div slot="left">
    Right figure shows only the index-finger keyvectors: from the MCP joint to the fingertip, from the fingertip to the thumb tip, from the PIP joint to
    the PIP joints of the middle and ring fingers, and from PIP joint to the pinky’s DIP joint. Iterating this process from the thumb to pinky and eliminating duplicates results in 15
    unique keyvectors. Incorporating these keyvectors into the optimization captures the majority of the grasping
    types: for pinch grasping, minimizing inter-finger distances aligns robotic
    and human hand poses to reduce operator strain, whereas for power grasping, preserving fingertip-to-palm
    distances are prioritized.
  </div>
  <Figure slot="right">
    <Image slot="figure" source={hand_retargeting} altText="Hand keypoint vectors." class="w-full" />
    <span slot="caption">Hand keypoint vectors.</span>
  </Figure>
</TwoColumns>

## Results

### In-hand Manipulation Results

<div>
We evaluate three canonical in-hand manipulation primitives—(i) regrasping to translate objects between
fingers, (ii) sliding objects relative to the palm, and (iii) rotating objects or their components, and instantiate
them in four benchmark tasks: (1) regrasping a bottle from a precision to a power grasp; (2) multi-object
grasping; (3) lid unscrewing; and (4) push-to-open lids.
</div>

<Figure>
  <Image slot="figure" source={experiment} altText="In-hand manipulation tasks." class="w-full" />
  <span slot="caption">In-hand manipulation tasks.</span>
</Figure>


### Long-Horizon Teleoperation Results

<div>
We evaluated the system’s long-horizon teleoperation capabilities through a table organization task involving a
cluttered workspace populated with randomly arranged cosmetic and skincare items, including serum bottles,
cream tubes, lipsticks, brushes, and powder palettes. A multi-drawer makeup organizer was placed adjacent
to the clutter, requiring the robotic hand-arm system to retrieve objects and place these in the organizer,
additionally, insert items into a drawer. The system successfully
managed diverse geometries and recovered from grasp slippage through real-time adjustments, demonstrating
robust performance in unstructured environments.
</div>

<Figure>
  <Image slot="figure" source={long_horizon} altText="Our hand-arm teleoperation system successfully grasps various items during a long-horizon table organization task." class="w-full" />
  <span slot="caption">Our hand-arm teleoperation system successfully grasps various items during a long-horizon table organization task.</span>
</Figure>

## Citation

```bibtex
@misc{bytedance2025bdex,
  author = "{ByteDance Seed}",
  title = "Enabling 20-DoF ByteDexter Hand Dexterous Teleoperation through Human Motion Retargeting",
  year = "2025",
  howpublished = "\url{}",
}
```